{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (58,59,65) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "C:\\Users\\skye.toor\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33430    my name is justin graham and i live in whiteth...\n",
       "11336    my name is leslie kay and i live in smyrna geo...\n",
       "41523    i am writing to support the noaction alternati...\n",
       "31393    my name is ms pogel and i live in fort lauderd...\n",
       "46876    i totally object to more dirty energy developm...\n",
       "41105    i am writing to support the noaction alternati...\n",
       "38241    dear friends at the national forest service an...\n",
       "27719    i am writing to support the noaction alternati...\n",
       "41344    i am writing to support the noaction alternati...\n",
       "29757    i am writing to support the noaction alternati...\n",
       "Name: stemmed, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re, os, csv \n",
    "import pandas as pd \n",
    "\n",
    "test_df = pd.read_csv('data/fs_comments.csv')\n",
    "test_df = test_df.sample(4000)\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(tokenizer=word_tokenize, stop_words='english')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "test_df[\"comment\"] = test_df['comment'].str.replace('[^\\w\\s]','')\n",
    "test_df['stemmed'] = test_df['comment'].apply(lambda x: stemmer.stem(str(x).lower())) \n",
    "test_df['stemmed'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_list = pd.read_csv('data/inequity_seed_list.csv')\n",
    "seed_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_folder = 'configs/'\n",
    "config_file = 'IMDB-pos-neg.yaml'\n",
    "\n",
    "with open(config_file_folder + config_file) as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "    \n",
    "categories = config['categories']\n",
    "seed_words = config['seed_words']\n",
    "output_file = config['kw_file']\n",
    "corpus_path = config['train_corpus_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "# the acceptable POS tags, may vary based on the task (topic/sentiment classification)\n",
    "ACCEPTABLE_TAGS_TOPIC = set(['FW', 'NN', 'NNS', 'NNP', 'NNPS']) \n",
    "ACCEPTABLE_TAGS_SENTIMENT = set(['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS'])\n",
    "ACCEPTABLE_TAGS_SENTIMENT = set(['JJ', 'JJR', 'JJS'])\n",
    "def is_valid_topic(word):\n",
    "    tag = pos_tag([word])[0][1]  # pos_tag returns [('cat', 'NN')]\n",
    "    if tag in ACCEPTABLE_TAGS_TOPIC:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_valid_sentiment(word):\n",
    "    tag = pos_tag([word])[0][1]  # pos_tag returns [('cat', 'NN')]\n",
    "    if tag in ACCEPTABLE_TAGS_SENTIMENT:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD = 5\n",
    "\n",
    "def tokenize(text, lower_case=True):\n",
    "    if lower_case:\n",
    "        text = text.lower()\n",
    "    tokens = tokenizer(text)\n",
    "    return [token.text for token in tokens if token.text.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"COMMENTSFILE.csv\")\n",
    "\n",
    "# replace the label index with the label\n",
    "df['label'] = df['label'].apply(lambda x: all_classes[int(x)-1])\n",
    "df['text'] = df.apply(lambda x: x['title'].lower() + ' ' + x['description'].lower(), axis=1)\n",
    "\n",
    "df = df[df['label'].isin(categories)]\n",
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMI\n",
    "MIN_COOCCURENCE = 3\n",
    "output_keywords = list()\n",
    "for s in seed_words:\n",
    "    seed_docs = inverted_index[s]\n",
    "    result = dict()\n",
    "    for w, docs in inverted_index.items():\n",
    "        #if w == s:  # skip the seed word itself\n",
    "        #    continue\n",
    "        cand_docs = inverted_index[w]\n",
    "        intersection = len(seed_docs.intersection(cand_docs))\n",
    "        if intersection < MIN_COOCCURENCE:\n",
    "            continue\n",
    "        pmi = log(intersection*num_train_docs/(len(cand_docs)*len(seed_docs)))\n",
    "        pmi_freq = pmi * log(intersection)\n",
    "        result[w] = pmi_freq\n",
    "    top_keywords = sorted(result, key=result.get, reverse=True)[:200]\n",
    "    print(\"Seedword:\", s)\n",
    "    print(top_keywords[:16])\n",
    "    if output_file.startswith('20NG') or output_file.startswith('AGNews') or output_file.startswith(\"NYT\"):\n",
    "        filtered_top_keywords = [kw for kw in top_keywords if is_valid_topic(kw)]\n",
    "    elif output_file.startswith('IMDB') or output_file.startswith('Yelp'):\n",
    "        filtered_top_keywords = [kw for kw in top_keywords if is_valid_sentiment(kw)]\n",
    "    else:\n",
    "        print(\"Dataset unknown:\", output_file)\n",
    "    print(filtered_top_keywords[:16])\n",
    "    output_keywords.append(filtered_top_keywords[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMR\n",
    "MIN_COOCCURENCE = 3\n",
    "output_keywords = list()\n",
    "result = dict()\n",
    "\n",
    "for w, docs in inverted_index.items():\n",
    "    cand_docs = inverted_index[w]\n",
    "    scores = list()\n",
    "    if output_file.startswith('20NG') or output_file.startswith('AGNews') or output_file.startswith(\"NYT\"):\n",
    "        if not is_valid_topic(w):\n",
    "            continue\n",
    "    elif output_file.startswith('IMDB') or output_file.startswith('Yelp'):\n",
    "        if not is_valid_sentiment(w):\n",
    "            continue\n",
    "    else:\n",
    "        print(\"Dataset unknown:\", output_file)\n",
    "        continue\n",
    "        \n",
    "    for s in seed_words:\n",
    "        seed_docs = inverted_index[s]\n",
    "        #if w == s:  # skip the seed word itself\n",
    "        #    continue\n",
    "        intersection = len(seed_docs.intersection(cand_docs))\n",
    "        if intersection < MIN_COOCCURENCE:\n",
    "            pmi_freq == 0\n",
    "        else: \n",
    "            pmi = log(intersection*num_train_docs/(len(cand_docs)*len(seed_docs)))\n",
    "            pmi = log(len(cand_docs)) * pmi\n",
    "        scores.append(pmi)\n",
    "    result[w] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate(seed_words):\n",
    "    top_keywords = sorted(result.items(), key=lambda kv: kv[1][i]-max(kv[1][1-i], 0), reverse=True)\n",
    "    print(top_keywords[:16])\n",
    "    output_keywords.append([k for k, _ in top_keywords[:16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_keywords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
